{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c5284-e5bb-4361-a348-e99d68867dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\dye37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering complete, results have been saved to Target_search.csv\n",
      "Similarity calculation and data extraction are complete. The results have been saved to Similarity_search.csv\n",
      "Image generation is complete.\n",
      "c1ccc2c(c1)Cc1ccccc1O2\n",
      "Molecules containing the substructure have been saved to the 'Sub_search.csv' file.\n",
      "Image generation is complete.\n",
      "use GPU\n",
      "All molecules are valid molecules.\n",
      "Processing dgl graphs from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\dye37\\lib\\site-packages\\ipykernel_launcher.py:513: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file pred_dataset.bin has been deleted.\n",
      "[[6.0486652e+02 6.6004700e+02 1.6649152e-01 4.8799920e+00]]\n"
     ]
    }
   ],
   "source": [
    "from rdkit import DataStructs\n",
    "from rdkit.DataStructs import ExplicitBitVect\n",
    "from rdkit.Chem import MACCSkeys\n",
    "import xlsxwriter\n",
    "from rdkit.Chem import Draw\n",
    "from io import BytesIO\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "from tkinter import *\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import dgl\n",
    "from dgllife.utils import smiles_to_bigraph\n",
    "from dgllife.utils import AttentiveFPAtomFeaturizer, AttentiveFPBondFeaturizer\n",
    "from dgllife.data import MoleculeCSVDataset\n",
    "from dgllife.model.gnn import AttentiveFPGNN\n",
    "from dgllife.model.readout import AttentiveFPReadout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolStandardize\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageTk\n",
    "from pathlib import Path\n",
    "\n",
    "# Main Window\n",
    "class WelcomeWindow:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title('dye-predictor')\n",
    "        master.config(background='#FEFEFE')\n",
    "        master.resizable(False, False)\n",
    "\n",
    "        image = Image.open(\"./Data/p1.png\")\n",
    "        img = image.resize((1020, 600))\n",
    "        self.my_img = ImageTk.PhotoImage(img)\n",
    "        self.background_label = Label(master, image=self.my_img)\n",
    "        self.background_label.grid(row=0, column=0, rowspan=4)\n",
    "\n",
    "        self.retrieval_button = tk.Button(master, text=\"Flourescent Dye Retrieval\", command=self.open_search_wind, font=('Arial', 15),bg='#FFFFFF', relief=tk.RAISED, width=25, borderwidth=4)\n",
    "        self.retrieval_button.grid(row=2, column=0, pady=20, sticky=\"s\")\n",
    "        self.prediction_button = tk.Button(master, text=\"Flourescent Dye Prediction\", command=self.open_predict_wind, font=('Arial', 15),bg='#FFFFFF', relief=tk.RAISED, width=25, borderwidth=4)\n",
    "        self.prediction_button.grid(row=3, column=0, pady=20, sticky=\"n\")\n",
    "\n",
    "    def open_search_wind(self):\n",
    "        self.master.withdraw()\n",
    "        root = tk.Toplevel(self.master)\n",
    "        app = search_app(root)\n",
    "    def open_predict_wind(self):\n",
    "        self.master.withdraw()\n",
    "        root = tk.Toplevel(self.master)\n",
    "        app = predict_app(root)\n",
    "\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "# Search Feature Code\n",
    "\n",
    "class search_app:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title('Flourescent Dye Retrieval')\n",
    "        master.resizable(False, False)\n",
    "        \n",
    "        image1 = Image.open(\"./Data/p2.png\")\n",
    "        img1 = image1.resize((1025, 100))\n",
    "        self.my_img1 = ImageTk.PhotoImage(img1)\n",
    "        self.background_label1 = Label(master, image=self.my_img1)\n",
    "        self.background_label1.grid(row=0, column=0, columnspan=10)\n",
    "        self.canvas1 = tk.Canvas(master, width=1025, height=320, bg=\"#FFFFFF\")\n",
    "        self.canvas1.grid(row=1, column=0, rowspan=8, columnspan=10)\n",
    "        \n",
    "        # Insert the input entry\n",
    "        self.label_smiles1 = tk.Label(master, text=\"Please input a SMILES for the target molecule\", font=('Arial', 12, \"bold\"), fg='#233C6F', bg='#FFFFFF')\n",
    "        self.label_smiles1.grid(row=1, column=0, pady=5, columnspan=10)\n",
    "        self.entry_smiles1 = tk.Entry(master, width=100)\n",
    "        self.entry_smiles1.grid(row=2, column=0, pady=5, columnspan=10)\n",
    "        self.entry_smiles1.insert(0, \"Such as: CCOC(=O)c1ccccc1-c1c2ccc(=[N+](CC)CC)cc-2oc2c1c(=O)oc1cc3c(cc12)CCCN3C\")\n",
    "         \n",
    "        # Insert Function Selection Button\n",
    "        self.label_function1 = tk.Label(master, text=\"Please select a function\", font=('Arial', 12, \"bold\"), fg='#233C6F', bg='#FFFFFF')\n",
    "        self.label_function1.grid(row=3, column=0, pady=5, columnspan=10)\n",
    "        self.selected_option = tk.IntVar(value=1)\n",
    "        self.query_button1 = tk.Radiobutton(master, text=\"Direct Retrieval\", variable=self.selected_option, value=1, font=('Arial', 13, \"bold\"), bg='#FFFFFF')\n",
    "        self.query_button1.grid(row=4, column=4, pady=5, columnspan=10 ,sticky=\"w\")\n",
    "        self.similarity_search_button1 = tk.Radiobutton(master, text=\"Similarity Search\", variable=self.selected_option, value=2, font=('Arial', 13, \"bold\"), bg='#FFFFFF')\n",
    "        self.similarity_search_button1.grid(row=5, column=4, pady=5, columnspan=10,sticky=\"w\")\n",
    "        self.sub_search_button1 = tk.Radiobutton(master, text=\"Substructure Search\", variable=self.selected_option, value=3, font=('Arial', 13, \"bold\"), bg='#FFFFFF')\n",
    "        self.sub_search_button1.grid(row=6, column=4, pady=5, columnspan=10,sticky=\"w\")\n",
    "        \n",
    "        # Insert Run Button\n",
    "        self.run_button1 = tk.Button(master, text=\"Run\", command=self.run_search, font=('Arial', 13, \"bold\"), bg='#24A5C8', relief=tk.RAISED, width=10)\n",
    "        self.run_button1.grid(row=7, column=0, pady=5, columnspan=10)\n",
    "\n",
    "        # Insert Function Transformation Button\n",
    "        self.to_prediction_button = tk.Button(master, text=\"Go to Prediction\", command=self.return_to_prediction, font=('Arial', 13), bg='#FFFFFF', relief=tk.RAISED, width=20)\n",
    "        self.to_prediction_button.grid(row=8, column=0, columnspan=10)\n",
    "\n",
    "        # Insert Tips\n",
    "        image3 = Image.open(\"./Data/p4.png\")\n",
    "        img3 = image3.resize((1025, 200))\n",
    "        self.my_img3 = ImageTk.PhotoImage(img3)\n",
    "        self.background_label3 = Label(master, image=self.my_img3)\n",
    "        self.background_label3.grid(row=9, column=0, columnspan=10)\n",
    "\n",
    "    def return_to_prediction(self):\n",
    "        self.master.withdraw()\n",
    "        root = tk.Toplevel(self.master)\n",
    "        app = predict_app(root)\n",
    "        \n",
    "###################################################\n",
    "# Pre-search Preparation\n",
    "    \n",
    "    def run_search(self):\n",
    "        try:\n",
    "            def standardize_smiles(smiles):\n",
    "                try:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    if mol:\n",
    "                        standardized_mol = normalizer.standardize(mol)\n",
    "                        return Chem.MolToSmiles(standardized_mol)\n",
    "                    else:\n",
    "                        return None\n",
    "                except:\n",
    "                    return None\n",
    "                    \n",
    "            # # Generate Morgan fingerprints for the molecules to be queried\n",
    "            def generate_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol is not None:\n",
    "                    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "                    return list(fp)\n",
    "                else:\n",
    "                    return [None] * n_bits\n",
    "\n",
    "            smiles_input = self.entry_smiles1.get().strip()\n",
    "            smiles_list = smiles_input.split(',')\n",
    "            df = pd.DataFrame({'SMILES': smiles_list})\n",
    "            cols = ['SMILES']\n",
    "            df = df[cols]\n",
    "            \n",
    "            normalizer = MolStandardize.Standardizer()\n",
    "            df['SMILES'] = df['SMILES'].apply(standardize_smiles)\n",
    "            df_valid = df.dropna(subset=['SMILES'])\n",
    "            l2 = len(df_valid)\n",
    "            \n",
    "            if l2 == 0:\n",
    "                print(\"The input molecule cannot be recognized. Please re-enter!\")\n",
    "                \n",
    "            output_file = 'Process_data/que-data.csv'\n",
    "            df_valid.to_csv(output_file, index=False)\n",
    "            \n",
    "            df = pd.read_csv('Process_data/que-data.csv')\n",
    "            df['Morgan_Fingerprint'] = df['SMILES'].apply(lambda x: generate_morgan_fingerprint(x))\n",
    "            fingerprints_df = pd.DataFrame(df['Morgan_Fingerprint'].tolist())\n",
    "            fingerprints_df.to_csv('Process_data/que-morgan.csv', index=False)\n",
    "\n",
    "            if not smiles_input:\n",
    "                messagebox.showerror(\"Error\", \"Please enter a SMILES string.\")\n",
    "                return\n",
    "            \n",
    "###################################################\n",
    "# Direct Search\n",
    "    \n",
    "            if self.selected_option.get() == 1:\n",
    "                messagebox.showinfo(\"Query\", f\"Searching for molecule: {smiles_input}\")\n",
    "                file1 = pd.read_csv('Process_data/que-data.csv')\n",
    "                file2 = pd.read_csv('./Data/Data_all_name.csv')\n",
    "                smiles_list = file1['SMILES'].tolist()\n",
    "                filtered_rows = file2[file2['SMILES'].isin(smiles_list)]\n",
    "                filtered_rows.to_csv('Results/Target_search.csv', index=False)\n",
    "                print(\"Filtering complete, results have been saved to Target_search.csv\")\n",
    "\n",
    "###################################################\n",
    "# Executing the similarity search function\n",
    "\n",
    "            elif self.selected_option.get() == 2:\n",
    "                messagebox.showinfo(\"Similarity Search\", f\"Performing molecule similarity search: {smiles_input}\")\n",
    "                rank = 100\n",
    "                def array_to_bitvector(fp_array):\n",
    "                    bitvect = ExplicitBitVect(len(fp_array))\n",
    "                    for i, bit in enumerate(fp_array):\n",
    "                        if bit == 1:\n",
    "                            bitvect.SetBit(i)\n",
    "                    return bitvect\n",
    "                file1 = pd.read_csv('Process_data/que-morgan.csv')\n",
    "                file2 = pd.read_csv('./Data/Data_all_morgan.csv')\n",
    "                file3 = pd.read_csv('./Data/Data_all_name.csv')\n",
    "                fp1 = file1.iloc[0].values\n",
    "                fp1_vect = array_to_bitvector(fp1)\n",
    "                fps2 = file2.apply(lambda row: array_to_bitvector(row.values), axis=1)\n",
    "                \n",
    "                # Calculating the Tanimoto similarity between the target molecule and all molecules in the database.\n",
    "                similarities = [DataStructs.TanimotoSimilarity(fp1_vect, fp2) for fp2 in fps2]\n",
    "                file2['Similarity_to_fp1'] = similarities\n",
    "                top_100_indices = file2.nlargest(rank, 'Similarity_to_fp1').index\n",
    "                top_100_molecules = file3.iloc[top_100_indices]\n",
    "                top_100_molecules.to_csv('Results/Similarity_search.csv', index=False)\n",
    "\n",
    "                input_file_path = 'Results/Similarity_search.csv'\n",
    "                output_file_path = 'Results/Similarity_search.csv'\n",
    "                try:\n",
    "                    data = pd.read_csv(input_file_path)\n",
    "                    data.fillna('NA', inplace=True)\n",
    "                    data.to_csv(output_file_path, index=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing the file: {e}\")\n",
    "                    \n",
    "                input_file_path = 'Results/Similarity_search.csv'\n",
    "                output_file_path = 'Results/Similarity_search.csv'\n",
    "                try:\n",
    "                    data = pd.read_csv(input_file_path)\n",
    "                    data.insert(0, 'Synonym', range(1, len(data) + 1))\n",
    "                    data.to_csv(output_file_path, index=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing the file: {e}\")\n",
    "                print(\"Similarity calculation and data extraction are complete. The results have been saved to Similarity_search.csv\")\n",
    "                file_toexcel = \"Results/Similarity_search\"\n",
    "        \n",
    "                # Creating an Excel workbook.\n",
    "                file_name = file_toexcel\n",
    "                def mol_to_excel(file):\n",
    "                    header = ['Synonym', 'SMILES', 'Solvent', 'Ex (nm)', 'Em (nm)', 'ST (nm)', 'QY', 'AC(cm-1M-1)']\n",
    "                    item_style = {\n",
    "                        'align': 'center',\n",
    "                        'valign': 'vcenter',\n",
    "                        'top': 2,\n",
    "                        'left': 2,\n",
    "                        'right': 2,\n",
    "                        'bottom': 2,\n",
    "                        'text_wrap': 1\n",
    "                    }\n",
    "                    header_style = {\n",
    "                        'bold': 1,\n",
    "                        'valign': 'vcenter',\n",
    "                        'align': 'center',\n",
    "                        'top': 2,\n",
    "                        'left': 2,\n",
    "                        'right': 2,\n",
    "                        'bottom': 2\n",
    "                    }\n",
    "                \n",
    "                    workbook = xlsxwriter.Workbook(f'{file}.xlsx')\n",
    "                    ItemStyle = workbook.add_format(item_style)\n",
    "                    HeaderStyle = workbook.add_format(header_style)\n",
    "                    worksheet = workbook.add_worksheet()\n",
    "                \n",
    "                    worksheet.set_column('A:A', 38)\n",
    "                    worksheet.set_column('B:B', 40)\n",
    "                    worksheet.set_column('C:I', 20)\n",
    "                \n",
    "                    for ix_, i in enumerate(header):\n",
    "                        worksheet.write(0, ix_, i, HeaderStyle)\n",
    "                \n",
    "                    df = pd.read_csv(f'{file}.csv')\n",
    "                \n",
    "                    for i in range(df.shape[0]):\n",
    "                        synonym = df.iloc[i, 0]\n",
    "                        structure_smi = df.iloc[i, 1]\n",
    "                \n",
    "                        img_data_structure = BytesIO()\n",
    "                        c_structure = Chem.MolFromSmiles(structure_smi)\n",
    "                        img_structure = Draw.MolToImage(c_structure)\n",
    "                        img_structure.save(img_data_structure, format='PNG')\n",
    "                \n",
    "                        worksheet.set_row(i + 1, 185)\n",
    "                        worksheet.insert_image(i + 1, 0, 'f', {'x_scale': 0.9, 'y_scale': 0.8, 'image_data': img_data_structure, 'positioning': 1})\n",
    "                \n",
    "                        worksheet.write(i + 1, 1, structure_smi, ItemStyle)\n",
    "                \n",
    "                        for j in range(2, 8):\n",
    "                                    cell_value = df.iloc[i, j]\n",
    "                                    if pd.isna(cell_value):\n",
    "                                        cell_value = 'NA'\n",
    "                                    worksheet.write(i + 1, j, cell_value, ItemStyle)\n",
    "                    workbook.close()\n",
    "                \n",
    "                mol_to_excel(file_name)\n",
    "                print('Image generation is complete.')\n",
    "\n",
    "###################################################\n",
    "# Executing the substructure search function\n",
    "\n",
    "            elif self.selected_option.get() == 3:       \n",
    "                messagebox.showinfo(\"Substructure Search\", f\"Performing molecule Substructure search: {smiles_input}\")\n",
    "\n",
    "                # Input the substructure file path.\n",
    "                file1 = pd.read_csv('Process_data/que-data.csv')\n",
    "                substructure_smiles = file1['SMILES'].iloc[0]\n",
    "                print(substructure_smiles)\n",
    "                \n",
    "                # Input the database file path.\n",
    "                csv_file2 = \"./Data/Data_all.csv\"  \n",
    "                smiles_column = \"SMILES\"  \n",
    "                df = pd.read_csv(csv_file2)\n",
    "                \n",
    "                substructure = Chem.MolFromSmiles(substructure_smiles)\n",
    "                if substructure is None:\n",
    "                    raise ValueError(\"The SMILES format of the substructure is incorrect. Please check your inputÔºÅ\")\n",
    "                \n",
    "                # Filter molecules containing the substructure.\n",
    "                def contains_substructure(smiles):\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    if mol is None:\n",
    "                        return False\n",
    "                    return mol.HasSubstructMatch(substructure)\n",
    "                \n",
    "                # Apply filtering criteria.\n",
    "                df['Contains_Substructure'] = df[smiles_column].apply(contains_substructure)\n",
    "                matching_molecules = df[df['Contains_Substructure']]\n",
    "                matching_molecules.insert(0, 'Synonym', range(1, len(matching_molecules) + 1))\n",
    "                matching_molecules.to_csv('./Results/Sub_search.csv', index=False)\n",
    "                print(\"Molecules containing the substructure have been saved to the 'Sub_search.csv' file.\")\n",
    "                \n",
    "                file_toexcel = \"Results/Sub_search\"\n",
    "                # Creating an Excel workbook.\n",
    "                file_name = file_toexcel\n",
    "                def mol_to_excel(file):\n",
    "                    header = ['Synonym', 'SMILES', 'Solvent', 'Ex (nm)', 'Em (nm)', 'ST (nm)', 'QY', 'AC(cm-1M-1)']\n",
    "                    item_style = {\n",
    "                        'align': 'center',\n",
    "                        'valign': 'vcenter',\n",
    "                        'top': 2,\n",
    "                        'left': 2,\n",
    "                        'right': 2,\n",
    "                        'bottom': 2,\n",
    "                        'text_wrap': 1\n",
    "                    }\n",
    "                    header_style = {\n",
    "                        'bold': 1,\n",
    "                        'valign': 'vcenter',\n",
    "                        'align': 'center',\n",
    "                        'top': 2,\n",
    "                        'left': 2,\n",
    "                        'right': 2,\n",
    "                        'bottom': 2\n",
    "                    }\n",
    "                \n",
    "                    workbook = xlsxwriter.Workbook(f'{file}.xlsx')\n",
    "                    ItemStyle = workbook.add_format(item_style)\n",
    "                    HeaderStyle = workbook.add_format(header_style)\n",
    "                    worksheet = workbook.add_worksheet()\n",
    "                \n",
    "                    worksheet.set_column('A:A', 38)\n",
    "                    worksheet.set_column('B:B', 40)\n",
    "                    worksheet.set_column('C:I', 20)\n",
    "                \n",
    "                    for ix_, i in enumerate(header):\n",
    "                        worksheet.write(0, ix_, i, HeaderStyle)\n",
    "                \n",
    "                    df = pd.read_csv(f'{file}.csv')\n",
    "                \n",
    "                    for i in range(df.shape[0]):\n",
    "                        synonym = df.iloc[i, 0]\n",
    "                        structure_smi = df.iloc[i, 1]\n",
    "                \n",
    "                        img_data_structure = BytesIO()\n",
    "                        c_structure = Chem.MolFromSmiles(structure_smi)\n",
    "                        img_structure = Draw.MolToImage(c_structure)\n",
    "                        img_structure.save(img_data_structure, format='PNG')\n",
    "                \n",
    "                        worksheet.set_row(i + 1, 185)\n",
    "                        worksheet.insert_image(i + 1, 0, 'f', {'x_scale': 0.9, 'y_scale': 0.8, 'image_data': img_data_structure, 'positioning': 1})\n",
    "                \n",
    "                        worksheet.write(i + 1, 1, structure_smi, ItemStyle)\n",
    "                \n",
    "                        for j in range(2, 8):\n",
    "                                    cell_value = df.iloc[i, j]\n",
    "                                    if pd.isna(cell_value):\n",
    "                                        cell_value = 'NA'\n",
    "                                    worksheet.write(i + 1, j, cell_value, ItemStyle)\n",
    "                    workbook.close()\n",
    "                \n",
    "                mol_to_excel(file_name)\n",
    "                print('Image generation is complete.')\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "            \n",
    "\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "# Prediction Feature Code\n",
    "\n",
    "graph_feat_size = 256\n",
    "class predict_app:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title('Property_Prediction')\n",
    "        master.resizable(False, False)\n",
    "        \n",
    "        image2 = Image.open(\"./Data/p3.png\")\n",
    "        img2 = image2.resize((1025, 100))\n",
    "        self.my_img2 = ImageTk.PhotoImage(img2)\n",
    "        self.background_label2 = Label(master, image=self.my_img2)\n",
    "        self.background_label2.grid(row=0, column=0, columnspan=10)\n",
    "        self.canvas2 = tk.Canvas(master, width=1020, height=320, bg=\"#FFFFFF\")\n",
    "        self.canvas2.grid(row=1, column=0, rowspan=8, columnspan=10)\n",
    "\n",
    "        self.target_label2 = tk.Label(master, text=\"Please select the molecule type\", font=('Arial', 12, \"bold\"), fg='#233C6F', bg='#FFFFFF')\n",
    "        self.target_label2.grid(row=1, column=0, pady=5, columnspan=10)\n",
    "        self.target_combobox2 = ttk.Combobox(master, values=[\"xanthene\", \"cyanine\", \"all-types\"], width=76, font=('Arial', 13, \"bold\"))\n",
    "        self.target_combobox2.grid(row=2, column=0, pady=5, columnspan=10)\n",
    "        self.target_combobox2.current(0)\n",
    "\n",
    "        self.smiles_label2 = tk.Label(master, text=\"Please enter the fluorescent molecule SMILES\", font=('Arial', 12, \"bold\"), fg='#233C6F', bg='#FFFFFF')\n",
    "        self.smiles_label2.grid(row=3, column=0, pady=5, columnspan=10)\n",
    "        self.smiles_entry2 = tk.Entry(master, width=100)\n",
    "        self.smiles_entry2.grid(row=4, column=0, pady=5, columnspan=10)\n",
    "        self.smiles_entry2.insert(0, \"Such as: CCOC(=O)c1ccccc1-c1c2ccc(=[N+](CC)CC)cc-2oc2c1c(=O)oc1cc3c(cc12)CCCN3C\")\n",
    "        \n",
    "        self.solvent_label2 = tk.Label(master, text=\"Please enter the solvent molecule SMILES\", font=('Arial', 12, \"bold\"), fg='#233C6F', bg='#FFFFFF')\n",
    "        self.solvent_label2.grid(row=5, column=0, pady=5, columnspan=10)\n",
    "        self.solvent_entry2 = tk.Entry(master, width=100)\n",
    "        self.solvent_entry2.grid(row=6, column=0, pady=5, columnspan=10)\n",
    "        self.solvent_entry2.insert(0, \"Such as: CCO\")\n",
    "\n",
    "        self.run_button2 = tk.Button(master, text=\"Run\", command=self.run_predict, font=('Arial', 13, \"bold\"), bg='#24A5C8', relief=tk.RAISED, width=10)\n",
    "        self.run_button2.grid(row=7, column=0, pady=5, columnspan=10)\n",
    "        self.return_button2 = Button(master, text='Go to search', command=self.return_to_search, font=('Arial', 12),bg='#FFFFFF', relief=tk.RAISED)\n",
    "        self.return_button2.grid(row=8, column=0, pady=5, columnspan=10)\n",
    "\n",
    "        # Insert Tips\n",
    "        image4 = Image.open(\"./Data/p5.png\")\n",
    "        img4 = image4.resize((1025, 170))\n",
    "        self.my_img4 = ImageTk.PhotoImage(img4)\n",
    "        self.background_label4 = Label(master, image=self.my_img4)\n",
    "        self.background_label4.grid(row=9, column=0, columnspan=10)\n",
    "\n",
    "    def return_to_search(self):\n",
    "        self.master.withdraw()\n",
    "        root = tk.Toplevel(self.master)\n",
    "        app = search_app(root)\n",
    "\n",
    "    \n",
    "    def run_predict(self):\n",
    "        try:\n",
    "            smiles = self.smiles_entry2.get()\n",
    "            solvent = self.solvent_entry2.get()\n",
    "            target = self.target_combobox2.get()\n",
    "            \n",
    "            n_tasks = 4\n",
    "            dropout_g = 0.4\n",
    "            dropout_f = 0.5\n",
    "            dropout_l = 0.4\n",
    "            fp_size = 1024\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                print('use GPU')\n",
    "                device = 'cuda'\n",
    "            else:\n",
    "                print('use CPU')\n",
    "                device = 'cpu'\n",
    "\n",
    "            seed = 42\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            \n",
    "            def set_random_seed(seed=42):\n",
    "                random.seed(seed)\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.manual_seed(seed)\n",
    "            \n",
    "            atom_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
    "            bond_featurizer = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
    "            n_feats = atom_featurizer.feat_size('hv')\n",
    "            e_feats = bond_featurizer.feat_size('he')\n",
    "\n",
    "            if target == 'xanthene':\n",
    "                train_data = pd.read_csv('./Data/train_xanthene.csv')\n",
    "                valid_data = pd.read_csv('./Data/valid_xanthene.csv')\n",
    "            if target == 'cyanine':\n",
    "                train_data = pd.read_csv('./Data/train_cyanine.csv')\n",
    "                valid_data = pd.read_csv('./Data/valid_cyanine.csv')\n",
    "            if target == 'all-types':\n",
    "                train_data = pd.read_csv('./Data/train_all_types.csv')\n",
    "                valid_data = pd.read_csv('./Data/valid_all_types.csv')\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            train_data[['AM', 'EM', 'QY', 'LGAC']] = scaler.fit_transform(train_data[['AM', 'EM', 'QY', 'LGAC']])\n",
    "            valid_data[['AM', 'EM', 'QY', 'LGAC']] = scaler.transform(valid_data[['AM', 'EM', 'QY', 'LGAC']])\n",
    "        \n",
    "            def load_data_with_fp(data, fp_data, name, load):\n",
    "                dataset = MoleculeCSVDataset(data,\n",
    "                                             smiles_to_graph=smiles_to_bigraph,\n",
    "                                             node_featurizer=atom_featurizer,\n",
    "                                             edge_featurizer=bond_featurizer,\n",
    "                                             smiles_column='SMILES',\n",
    "                                             cache_file_path=str(name)+'_dataset.bin',\n",
    "                                             task_names=['AM','EM','QY','LGAC'],\n",
    "                                             load=load, init_mask=True, n_jobs=1\n",
    "                                            )\n",
    "            \n",
    "                combined_data = []\n",
    "                for i, data_tuple in enumerate(dataset):\n",
    "                    if len(data_tuple) == 3:\n",
    "                        smiles, graph, label = data_tuple\n",
    "                        mask = None\n",
    "                    else:\n",
    "                        smiles, graph, label, mask = data_tuple\n",
    "                    fp = torch.tensor(fp_data[i], dtype=torch.float32)\n",
    "                    combined_data.append((graph, fp, label, mask))\n",
    "                return combined_data\n",
    "            \n",
    "            class GraphFingerprintsModel(nn.Module):\n",
    "                def __init__(self, node_feat_size, edge_feat_size, fp_size,\n",
    "                             graph_feat_size=graph_feat_size, num_layers=2, num_timesteps=2,\n",
    "                             n_tasks=4, dropout_g=0, dropout_f=0, dropout_l=0):\n",
    "                    super(GraphFingerprintsModel, self).__init__()\n",
    "            \n",
    "                    self.gnn = AttentiveFPGNN(node_feat_size=node_feat_size,\n",
    "                                              edge_feat_size=edge_feat_size,\n",
    "                                              num_layers=num_layers,\n",
    "                                              graph_feat_size=graph_feat_size,\n",
    "                                              dropout=dropout_g)\n",
    "                    self.readout = AttentiveFPReadout(feat_size=graph_feat_size,\n",
    "                                                      num_timesteps=num_timesteps,\n",
    "                                                      dropout=dropout_g)\n",
    "            \n",
    "                    self.fp_fc = nn.Sequential(\n",
    "                        nn.Linear(fp_size, 256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(dropout_f),\n",
    "                        nn.Linear(256, graph_feat_size)\n",
    "                    )\n",
    "            \n",
    "                    self.predict = nn.Sequential(\n",
    "                        nn.Dropout(dropout_l),\n",
    "                        nn.Linear(graph_feat_size * 2, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, n_tasks)\n",
    "                    )\n",
    "            \n",
    "                def forward(self, g, node_feats, edge_feats, fingerprints):\n",
    "                    if edge_feats is None or 'he' not in g.edata.keys():\n",
    "                        num_edges = g.number_of_edges()\n",
    "                        edge_feats = torch.zeros((num_edges, e_feats)).to(g.device)\n",
    "                    node_feats = self.gnn(g, node_feats, edge_feats)\n",
    "                    graph_feats = self.readout(g, node_feats)\n",
    "                    fp_feats = self.fp_fc(fingerprints)\n",
    "                    combined_feats = torch.cat([graph_feats, fp_feats], dim=1)\n",
    "                    return self.predict(combined_feats)\n",
    "            \n",
    "            class MolecularDataset(Dataset):\n",
    "                def __init__(self, data):\n",
    "                    self.data = data\n",
    "            \n",
    "                def __len__(self):\n",
    "                    return len(self.data)\n",
    "            \n",
    "                def __getitem__(self, idx):\n",
    "                    return self.data[idx]\n",
    "            \n",
    "            def collate_fn(batch):\n",
    "                graphs, fps, labels, masks = zip(*batch)\n",
    "                graphs = dgl.batch(graphs)\n",
    "                fps = torch.stack(fps)\n",
    "                labels = torch.stack(labels)\n",
    "                masks = torch.stack(masks) if masks[0] is not None else None\n",
    "                return graphs, fps, labels, masks\n",
    "        \n",
    "            model = GraphFingerprintsModel(node_feat_size=n_feats,\n",
    "                                           edge_feat_size=e_feats,\n",
    "                                           graph_feat_size=graph_feat_size,\n",
    "                                           num_layers=2,\n",
    "                                           num_timesteps=2,\n",
    "                                           fp_size=fp_size,\n",
    "                                           n_tasks=4,\n",
    "                                           dropout_g=dropout_g,\n",
    "                                           dropout_f=dropout_f,\n",
    "                                           dropout_l=dropout_l).to(device)\n",
    "            \n",
    "            if target == 'xanthene':\n",
    "                model.load_state_dict(torch.load('./Data/Model_xanthene.pth', map_location=device))\n",
    "            if target == 'cyanine':\n",
    "                model.load_state_dict(torch.load('./Data/Model_cyanine.pth', map_location=device))\n",
    "            if target == 'all-types':\n",
    "                model.load_state_dict(torch.load('./Data/Model_all_types.pth', map_location=device))\n",
    "                \n",
    "            def predict(model, dataloader):\n",
    "                all_predictions = []\n",
    "                with torch.no_grad():\n",
    "                    for graphs, fps, _, _ in dataloader:\n",
    "                        graphs = graphs.to(device)\n",
    "                        fps = fps.to(device)\n",
    "            \n",
    "                        node_feats = graphs.ndata['hv']\n",
    "                        edge_feats = graphs.edata['he']\n",
    "            \n",
    "                        predictions = model(graphs, node_feats, edge_feats, fps)\n",
    "                        all_predictions.append(predictions.cpu().numpy())\n",
    "            \n",
    "                return np.vstack(all_predictions)\n",
    "            \n",
    "            def save_predictions(predictions, file_name):\n",
    "                df = pd.DataFrame(predictions, columns=['AM','EM','QY','LGAC'])\n",
    "                df.to_csv(file_name, index=False)\n",
    "\n",
    "            def reverse_standardization(predictions, scaler):\n",
    "                return scaler.inverse_transform(predictions)\n",
    "            \n",
    "            def standardize_smiles(smiles):\n",
    "                try:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    if mol:\n",
    "                        standardized_mol = normalizer.standardize(mol)\n",
    "                        return Chem.MolToSmiles(standardized_mol)\n",
    "                    else:\n",
    "                        return None\n",
    "                except:\n",
    "                    return None\n",
    "            \n",
    "            def generate_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol is not None:\n",
    "                    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "                    return list(fp)\n",
    "                else:\n",
    "                    return [None] * n_bits\n",
    "                    \n",
    "            def load_fingerprint(fp_file):\n",
    "                df = pd.read_csv(fp_file)\n",
    "                return torch.tensor(df.values, dtype=torch.float32)\n",
    "        \n",
    "            if not smiles or not solvent:\n",
    "                messagebox.showwarning(\"Input Error\", \"Please provide SMILES and Solvent input.\")\n",
    "                return\n",
    "                \n",
    "            smiles_list = smiles.split(',')\n",
    "            solvent_list = solvent.split(',')\n",
    "        \n",
    "            if len(smiles_list) != len(solvent_list):\n",
    "                messagebox.showwarning(\"Input Error\", \"The number of SMILES and Solvent entries does not match.\")\n",
    "                return\n",
    "        \n",
    "            df = pd.DataFrame({\n",
    "                'SMILES': smiles_list,\n",
    "                'Solvent': solvent_list,\n",
    "                'AM': None,\n",
    "                'EM': None,\n",
    "                'QY': None,\n",
    "                'LGAC': None\n",
    "            })\n",
    "        \n",
    "            cols = ['SMILES', 'Solvent', 'AM', 'EM', 'QY', 'LGAC']\n",
    "            df = df[cols]\n",
    "            df.to_csv('Process_data/pred-prep.csv', index=False)\n",
    "        \n",
    "            file_path = 'Process_data/pred-prep.csv'\n",
    "            df = pd.read_csv(file_path)\n",
    "            normalizer = MolStandardize.Standardizer()\n",
    "            df['SMILES'] = df['SMILES'].apply(standardize_smiles)\n",
    "            df_valid = df.dropna(subset=['SMILES'])\n",
    "            l1= len(df)\n",
    "            l2 = len(df_valid)\n",
    "            s = l1-l2\n",
    "            if l1 == l2:\n",
    "                print('All molecules are valid molecules.')\n",
    "            else:\n",
    "                print('There are', s, 'invalid molecules, which have been deleted.')\n",
    "            output_file = 'Process_data/pred-data.csv'\n",
    "            df_valid.to_csv(output_file, index=False)\n",
    "    \n",
    "            df = pd.read_csv('Process_data/pred-data.csv')\n",
    "            df['Morgan_Fingerprint'] = df['Solvent'].apply(lambda x: generate_morgan_fingerprint(x))\n",
    "            fingerprints_df = pd.DataFrame(df['Morgan_Fingerprint'].tolist())\n",
    "            fingerprints_df.to_csv('Process_data/pred-morgan.csv', index=False)\n",
    "        \n",
    "            pred_data = pd.read_csv('Process_data/pred-data.csv')\n",
    "            pred_fp = load_fingerprint('Process_data/pred-morgan.csv')\n",
    "            \n",
    "            pred_data[['AM', 'EM', 'QY', 'LGAC']] = scaler.transform(pred_data[['AM', 'EM', 'QY', 'LGAC']])\n",
    "            \n",
    "            pred_datasets = load_data_with_fp(pred_data, pred_fp, 'pred', True)\n",
    "            pred_dataset = MolecularDataset(pred_datasets)\n",
    "            test_loader = DataLoader(pred_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "            test_predictions = predict(model, test_loader)\n",
    "            \n",
    "            test_scale_predictions = reverse_standardization(test_predictions, scaler)\n",
    "            save_predictions(test_scale_predictions, 'Results/pred-results.csv')\n",
    "            \n",
    "            file_name = 'pred_dataset.bin'\n",
    "            file_path = Path(file_name)\n",
    "            \n",
    "            if file_path.exists():\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                    print(f\"The file {file_name} has been deleted.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while deleting the file: {e}\")\n",
    "            else:\n",
    "                print(f\"The file {file_name} does not exist in the current directory.\")\n",
    "                \n",
    "            print(test_scale_predictions)\n",
    "        \n",
    "            \n",
    "            result_df = pd.read_csv('Results/pred-results.csv')\n",
    "            new_columns = list(result_df.columns)\n",
    "            new_columns[0:4] = ['Ex', 'Em', 'QY', 'Log(AC)']\n",
    "            result_df.columns = new_columns\n",
    "            result_df.iloc[:, :2] = result_df.iloc[:, :2].round(2)\n",
    "            result_df.to_csv('Results/pred-results.csv', index=False)\n",
    "    \n",
    "            selected_columns = result_df.iloc[:, :2]\n",
    "            rounded_columns = selected_columns.round(2)\n",
    "            rounded_df = pd.concat([rounded_columns, result_df.iloc[:, 2:]], axis=1)\n",
    "            messagebox.showinfo(\"Prediction complete\", f\"The prediction results have been saved to 'pred-results.csv'. Below is a preview of the results:\\n{rounded_df.head().to_string(index=False)}\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "# Main Code\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = WelcomeWindow(root)\n",
    "    root.mainloop()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb00a2e-8a10-4f62-9385-eeb30b54eb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb796219-998c-41ca-8e13-a8acc5dc91a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622a57b0-b14e-4aa0-a2a8-7d7528fc7cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f9104-264f-4afa-9f1e-bcf5c60d0128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dye37",
   "language": "python",
   "name": "dye37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
